{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      " ['ants', 'periods_test.csv', 'periods_test.feather', 'periods_train.csv', 'periods_train.feather', 'sample_submission.csv', 'test.csv', 'test.feather', 'test_active.csv', 'test_jpg', 'train.csv', 'train.feather', 'train_active.csv', 'train_jpg']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "notebookstart= time.time()\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "print(\"Data:\\n\",os.listdir(\"../input\"))\n",
    "\n",
    "# Models Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Gradient Boosting\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "# Viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLDS = 5\n",
    "SEED = 42\n",
    "VALID = True\n",
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None, seed_bool = True):\n",
    "        if(seed_bool == True):\n",
    "            params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "        \n",
    "def get_oof(clf, x_train, y, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        print('\\nFold {}'.format(i))\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "    \n",
    "def cleanName(text):\n",
    "    try:\n",
    "        textProc = text.lower()\n",
    "        # textProc = \" \".join(map(str.strip, re.split('(\\d+)',textProc)))\n",
    "        #regex = re.compile(u'[^[:alpha:]]')\n",
    "        #textProc = regex.sub(\" \", textProc)\n",
    "        textProc = re.sub('[!@#$_“”¨«»®´·º½¾¿¡§£₤‘’]', '', textProc)\n",
    "        textProc = \" \".join(textProc.split())\n",
    "        return textProc\n",
    "    except: \n",
    "        return \"name error\"\n",
    "    \n",
    "    \n",
    "def rmse(y, y0):\n",
    "    assert len(y) == len(y0)\n",
    "    return np.sqrt(np.mean(np.power((y - y0), 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2011862, 1467367)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./tfidf_features.pickle', 'rb') as f:\n",
    "    temp = pickle.load(f)\n",
    "    \n",
    "print(temp.shape)\n",
    "del temp; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: 1503424 Rows, 16 Columns\n",
      "Test shape: 508438 Rows, 16 Columns\n",
      "Combine Train and Test\n",
      "\n",
      "All Data shape: 2011862 Rows, 16 Columns\n",
      "Feature Engineering\n",
      "\n",
      "Create Time Variables\n",
      "\n",
      "Encode Variables\n",
      "Encoding : ['user_id', 'region', 'city', 'parent_category_name', 'category_name', 'user_type', 'image_top_1', 'param_1', 'param_2', 'param_3']\n",
      "\n",
      "Text Features\n"
     ]
    }
   ],
   "source": [
    "training = pd.read_csv('../input/train.csv', index_col = \"item_id\", parse_dates = [\"activation_date\"])\n",
    "traindex = training.index\n",
    "testing = pd.read_csv('../input/test.csv', index_col = \"item_id\", parse_dates = [\"activation_date\"])\n",
    "testdex = testing.index\n",
    "\n",
    "ntrain = training.shape[0]\n",
    "ntest = testing.shape[0]\n",
    "\n",
    "kf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "y = training.deal_probability.copy()\n",
    "training.drop(\"deal_probability\",axis=1, inplace=True)\n",
    "print('Train shape: {} Rows, {} Columns'.format(*training.shape))\n",
    "print('Test shape: {} Rows, {} Columns'.format(*testing.shape))\n",
    "\n",
    "print(\"Combine Train and Test\")\n",
    "df = pd.concat([training,testing],axis=0)\n",
    "del training, testing\n",
    "gc.collect()\n",
    "print('\\nAll Data shape: {} Rows, {} Columns'.format(*df.shape))\n",
    "\n",
    "\n",
    "print(\"Feature Engineering\")\n",
    "df[\"price\"] = np.log(df[\"price\"]+0.001)\n",
    "df[\"price\"].fillna(df.price.mean(),inplace=True)\n",
    "df[\"image_top_1\"].fillna(-999,inplace=True)\n",
    "\n",
    "print(\"\\nCreate Time Variables\")\n",
    "df[\"Weekday\"] = df['activation_date'].dt.weekday\n",
    "\n",
    "# Create Validation Index and Remove Dead Variables\n",
    "training_index = df.loc[df.activation_date<=pd.to_datetime('2017-04-07')].index\n",
    "validation_index = df.loc[df.activation_date>=pd.to_datetime('2017-04-08')].index\n",
    "df.drop([\"activation_date\",\"image\"],axis=1,inplace=True)\n",
    "\n",
    "print(\"\\nEncode Variables\")\n",
    "categorical = [\"user_id\",\"region\",\"city\",\"parent_category_name\",\"category_name\",\"user_type\",\"image_top_1\",\"param_1\",\"param_2\",\"param_3\"]\n",
    "print(\"Encoding :\",categorical)\n",
    "\n",
    "# Encoder:\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for col in categorical:\n",
    "    df[col].fillna('Unknown')\n",
    "    df[col] = lbl.fit_transform(df[col].astype(str))\n",
    "    \n",
    "print(\"\\nText Features\")\n",
    "\n",
    "# Feature Engineering \n",
    "\n",
    "# Meta Text Features\n",
    "textfeats = [\"description\", \"title\"]\n",
    "df['desc_punc'] = df['description'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "df['title'] = df['title'].apply(lambda x: cleanName(x))\n",
    "df[\"description\"]   = df[\"description\"].apply(lambda x: cleanName(x))\n",
    "\n",
    "for cols in textfeats:\n",
    "    df[cols] = df[cols].astype(str) \n",
    "    df[cols] = df[cols].astype(str).fillna('missing') # FILL NA\n",
    "    df[cols] = df[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
    "    df[cols + '_num_words'] = df[cols].apply(lambda comment: len(comment.split())) # Count number of Words\n",
    "    df[cols + '_num_unique_words'] = df[cols].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    df[cols + '_words_vs_unique'] = df[cols+'_num_unique_words'] / df[cols+'_num_words'] * 100 # Count Unique Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2011862, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>...</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>desc_punc</th>\n",
       "      <th>description_num_words</th>\n",
       "      <th>description_num_unique_words</th>\n",
       "      <th>description_words_vs_unique</th>\n",
       "      <th>title_num_words</th>\n",
       "      <th>title_num_unique_words</th>\n",
       "      <th>title_words_vs_unique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b912c3c6a6ad</th>\n",
       "      <td>884270</td>\n",
       "      <td>19</td>\n",
       "      <td>462</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>249</td>\n",
       "      <td>112</td>\n",
       "      <td>1217</td>\n",
       "      <td>кокоби(кокон для сна)</td>\n",
       "      <td>кокон для сна малыша,пользовались меньше месяц...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2dac0150717d</th>\n",
       "      <td>227908</td>\n",
       "      <td>17</td>\n",
       "      <td>1314</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>112</td>\n",
       "      <td>1217</td>\n",
       "      <td>стойка для одежды</td>\n",
       "      <td>стойка для одежды, под вешалки. с бутика.</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2723</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba83aefab5dc</th>\n",
       "      <td>576261</td>\n",
       "      <td>16</td>\n",
       "      <td>1290</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>112</td>\n",
       "      <td>1217</td>\n",
       "      <td>philips bluray</td>\n",
       "      <td>в хорошем состоянии, домашний кинотеатр с blu ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2260</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02996f1dd2ea</th>\n",
       "      <td>755087</td>\n",
       "      <td>21</td>\n",
       "      <td>950</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>38</td>\n",
       "      <td>112</td>\n",
       "      <td>1217</td>\n",
       "      <td>автокресло</td>\n",
       "      <td>продам кресло от0-25кг</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2838</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7c90be56d2ab</th>\n",
       "      <td>944363</td>\n",
       "      <td>4</td>\n",
       "      <td>318</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "      <td>124</td>\n",
       "      <td>46</td>\n",
       "      <td>ваз 2110, 2003</td>\n",
       "      <td>все вопросы по телефону.</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1408</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_id  region  city  parent_category_name  category_name  \\\n",
       "item_id                                                                    \n",
       "b912c3c6a6ad   884270      19   462                     4             42   \n",
       "2dac0150717d   227908      17  1314                     2             22   \n",
       "ba83aefab5dc   576261      16  1290                     0              2   \n",
       "02996f1dd2ea   755087      21   950                     4             42   \n",
       "7c90be56d2ab   944363       4   318                     6              0   \n",
       "\n",
       "              param_1  param_2  param_3                  title  \\\n",
       "item_id                                                          \n",
       "b912c3c6a6ad      249      112     1217  кокоби(кокон для сна)   \n",
       "2dac0150717d      122      112     1217      стойка для одежды   \n",
       "ba83aefab5dc       84      112     1217         philips bluray   \n",
       "02996f1dd2ea       38      112     1217             автокресло   \n",
       "7c90be56d2ab      278      124       46         ваз 2110, 2003   \n",
       "\n",
       "                                                    description  \\\n",
       "item_id                                                           \n",
       "b912c3c6a6ad  кокон для сна малыша,пользовались меньше месяц...   \n",
       "2dac0150717d          стойка для одежды, под вешалки. с бутика.   \n",
       "ba83aefab5dc  в хорошем состоянии, домашний кинотеатр с blu ...   \n",
       "02996f1dd2ea                             продам кресло от0-25кг   \n",
       "7c90be56d2ab                           все вопросы по телефону.   \n",
       "\n",
       "                      ...            user_type  image_top_1  Weekday  \\\n",
       "item_id               ...                                              \n",
       "b912c3c6a6ad          ...                    1           13        1   \n",
       "2dac0150717d          ...                    1         2723        6   \n",
       "ba83aefab5dc          ...                    1         2260        0   \n",
       "02996f1dd2ea          ...                    0         2838        5   \n",
       "7c90be56d2ab          ...                    1         1408        3   \n",
       "\n",
       "              desc_punc  description_num_words  description_num_unique_words  \\\n",
       "item_id                                                                        \n",
       "b912c3c6a6ad          2                      7                             7   \n",
       "2dac0150717d          3                      7                             7   \n",
       "ba83aefab5dc          5                     17                            17   \n",
       "02996f1dd2ea          1                      3                             3   \n",
       "7c90be56d2ab          1                      4                             4   \n",
       "\n",
       "              description_words_vs_unique  title_num_words  \\\n",
       "item_id                                                      \n",
       "b912c3c6a6ad                        100.0                3   \n",
       "2dac0150717d                        100.0                3   \n",
       "ba83aefab5dc                        100.0                2   \n",
       "02996f1dd2ea                        100.0                1   \n",
       "7c90be56d2ab                        100.0                3   \n",
       "\n",
       "              title_num_unique_words  title_words_vs_unique  \n",
       "item_id                                                      \n",
       "b912c3c6a6ad                       3                  100.0  \n",
       "2dac0150717d                       3                  100.0  \n",
       "ba83aefab5dc                       2                  100.0  \n",
       "02996f1dd2ea                       1                  100.0  \n",
       "7c90be56d2ab                       3                  100.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
