{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\osk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "import wordbatch\n",
    "from wordbatch.extractors import WordBag\n",
    "from wordbatch.models import FM_FTRL\n",
    "\n",
    "from myutils import reduce_mem_usage\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "lentrain = 1503424\n",
    "#stopwords_kernel = {x: 1 for x in stopwords.words('russian')}\n",
    "stopwords_kernel = list(set(stopwords.words('russian')))\n",
    "non_alphanums = re.compile(u'[^A-Za-z0-9]+')\n",
    "non_alphanumpunct = re.compile(u'[^A-Za-z0-9\\.?!,; \\(\\)\\[\\]\\'\\\"\\$]+')\n",
    "RE_PUNCTUATION = '|'.join([re.escape(x) for x in string.punctuation])\n",
    "stop_words = list(set(stopwords.words('russian')))\n",
    "russian_stop = set(stopwords.words('russian'))\n",
    "punctuation = string.punctuation\n",
    "\n",
    "textfeats = ['title', 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    text = text.lower().strip()\n",
    "    for s in string.punctuation:\n",
    "        text = text.replace(s, ' ')\n",
    "    text = text.strip().split(' ')\n",
    "    return u' '.join(x for x in text if len(x) > 1 and x not in stopwords_kernel)\n",
    "\n",
    "def rmse(predicted, actual):\n",
    "    return np.sqrt(((predicted - actual) ** 2).mean())\n",
    "\n",
    "def cleanName(text):\n",
    "    try:\n",
    "        textProc = text.lower()\n",
    "        # textProc = \" \".join(map(str.strip, re.split('(\\d+)',textProc)))\n",
    "        #regex = re.compile(u'[^[:alpha:]]')\n",
    "        #textProc = regex.sub(\" \", textProc)\n",
    "        textProc = re.sub('[!@#$_“”¨«»®´·º½¾¿¡§£₤‘’]', '', textProc)\n",
    "        textProc = \" \".join(textProc.split())\n",
    "        return textProc\n",
    "    except: \n",
    "        return \"name error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 2)\n",
      "(508438, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../input/train.csv', usecols=['description', 'title'])\n",
    "test = pd.read_csv('../input/test.csv', usecols=['description', 'title'])\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2011862, 2)\n",
      "Wall time: 67.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.concat([train, test])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'description', 'title_titleword_count',\n",
      "       'title_upper_case_word_count', 'title_num_stopwords',\n",
      "       'title_num_punctuations', 'title_num_alphabets', 'title_num_digits',\n",
      "       'title_num_chars', 'title_num_words', 'title_num_unique_words',\n",
      "       'title_chars_by_words', 'title_words_by_uniquewords',\n",
      "       'title_punctuations_by_chars', 'title_punctuations_by_words',\n",
      "       'title_digits_by_chars', 'title_alphabets_by_chars',\n",
      "       'title_stopwords_by_words', 'title_mean', 'description_titleword_count',\n",
      "       'description_upper_case_word_count', 'description_num_stopwords',\n",
      "       'description_num_punctuations', 'description_num_alphabets',\n",
      "       'description_num_digits', 'description_num_chars',\n",
      "       'description_num_words', 'description_num_unique_words',\n",
      "       'description_chars_by_words', 'description_words_by_uniquewords',\n",
      "       'description_punctuations_by_chars',\n",
      "       'description_punctuations_by_words', 'description_digits_by_chars',\n",
      "       'description_alphabets_by_chars', 'description_stopwords_by_words',\n",
      "       'description_mean'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>title_titleword_count</th>\n",
       "      <th>title_upper_case_word_count</th>\n",
       "      <th>title_num_stopwords</th>\n",
       "      <th>title_num_punctuations</th>\n",
       "      <th>title_num_alphabets</th>\n",
       "      <th>title_num_digits</th>\n",
       "      <th>title_num_chars</th>\n",
       "      <th>title_num_words</th>\n",
       "      <th>...</th>\n",
       "      <th>description_num_unique_words</th>\n",
       "      <th>description_chars_by_words</th>\n",
       "      <th>description_words_by_uniquewords</th>\n",
       "      <th>description_punctuations_by_chars</th>\n",
       "      <th>description_punctuations_by_words</th>\n",
       "      <th>description_digits_by_chars</th>\n",
       "      <th>description_alphabets_by_chars</th>\n",
       "      <th>description_stopwords_by_words</th>\n",
       "      <th>description_mean</th>\n",
       "      <th>title_description_len_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>кокоби(кокон для сна)</td>\n",
       "      <td>кокон для сна малыша,пользовались меньше месяц...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>7.250</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.206897</td>\n",
       "      <td>0.355932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>стойка для одежды</td>\n",
       "      <td>стойка для одежды, под вешалки. с бутика.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>5.125</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.707317</td>\n",
       "      <td>0.404762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>philips bluray</td>\n",
       "      <td>в хорошем состоянии, домашний кинотеатр с blu ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>5.500</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.717172</td>\n",
       "      <td>0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>автокресло</td>\n",
       "      <td>продам кресло от0-25кг</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ваз 2110, 2003</td>\n",
       "      <td>все вопросы по телефону.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4.800</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                        description  \\\n",
       "0  кокоби(кокон для сна)  кокон для сна малыша,пользовались меньше месяц...   \n",
       "1      стойка для одежды          стойка для одежды, под вешалки. с бутика.   \n",
       "2         philips bluray  в хорошем состоянии, домашний кинотеатр с blu ...   \n",
       "3             автокресло                             продам кресло от0-25кг   \n",
       "4         ваз 2110, 2003                           все вопросы по телефону.   \n",
       "\n",
       "   title_titleword_count  title_upper_case_word_count  title_num_stopwords  \\\n",
       "0                      0                            0                    1   \n",
       "1                      2                            0                    1   \n",
       "2                      1                            0                    0   \n",
       "3                      1                            0                    0   \n",
       "4                      0                            1                    0   \n",
       "\n",
       "   title_num_punctuations  title_num_alphabets  title_num_digits  \\\n",
       "0                       2                    0                 0   \n",
       "1                       0                    0                 0   \n",
       "2                       0                    0                 0   \n",
       "3                       0                    0                 0   \n",
       "4                       1                    0                 0   \n",
       "\n",
       "   title_num_chars  title_num_words             ...               \\\n",
       "0               21                3             ...                \n",
       "1               17                3             ...                \n",
       "2               14                2             ...                \n",
       "3               10                1             ...                \n",
       "4               14                3             ...                \n",
       "\n",
       "   description_num_unique_words  description_chars_by_words  \\\n",
       "0                             7                       7.250   \n",
       "1                             7                       5.125   \n",
       "2                            17                       5.500   \n",
       "3                             3                       5.500   \n",
       "4                             4                       4.800   \n",
       "\n",
       "   description_words_by_uniquewords  description_punctuations_by_chars  \\\n",
       "0                          0.875000                           0.033898   \n",
       "1                          0.875000                           0.071429   \n",
       "2                          0.944444                           0.050000   \n",
       "3                          0.750000                           0.043478   \n",
       "4                          0.800000                           0.040000   \n",
       "\n",
       "   description_punctuations_by_words  description_digits_by_chars  \\\n",
       "0                           0.250000                          0.0   \n",
       "1                           0.375000                          0.0   \n",
       "2                           0.277778                          0.0   \n",
       "3                           0.250000                          0.0   \n",
       "4                           0.200000                          0.0   \n",
       "\n",
       "   description_alphabets_by_chars  description_stopwords_by_words  \\\n",
       "0                             0.0                        0.125000   \n",
       "1                             0.0                        0.375000   \n",
       "2                             0.0                        0.222222   \n",
       "3                             0.0                        0.000000   \n",
       "4                             0.0                        0.400000   \n",
       "\n",
       "   description_mean  title_description_len_ratio  \n",
       "0          1.206897                     0.355932  \n",
       "1          1.707317                     0.404762  \n",
       "2          1.717172                     0.140000  \n",
       "3          1.363636                     0.434783  \n",
       "4          1.666667                     0.560000  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in textfeats:\n",
    "    df[col] = df[col].astype(str)\n",
    "    df[col] = df[col].fillna('missing')\n",
    "    df[col + '_titleword_count'] = df[col].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "    df[col + '_upper_case_word_count'] = df[col].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "\n",
    "    df[col] = df[col].str.lower()\n",
    "    df[col + '_num_stopwords'] = df[col].apply(lambda x: len([wrd for wrd in x.split() if wrd.lower() in stop_words]))\n",
    "    df[col + '_num_punctuations'] = df[col].apply(lambda x: len(\"\".join(_ for _ in x if _ in punctuation)))\n",
    "    df[col + '_num_alphabets'] = df[col].apply(lambda comment: len([c for c in comment if c.isupper()]))\n",
    "    df[col + '_num_digits'] = df[col].apply(lambda comment: (comment.count('[0-9]')))\n",
    "    df[col + '_num_chars'] = df[col].apply(len) # Count number of Characters\n",
    "    df[col + '_num_words'] = df[col].apply(lambda comment: len(comment.split())) # Count number of Words\n",
    "    df[col + '_num_unique_words'] = df[col].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    df[col + '_chars_by_words'] = df[col + '_num_chars'] / (df[col + '_num_words'] + 1)\n",
    "    df[col + '_words_by_uniquewords'] = df[col + '_num_unique_words'] / (df[col+'_num_words'] + 1)\n",
    "    df[col + '_punctuations_by_chars'] = df[col+'_num_punctuations'] / (df[col + '_num_chars'] + 1)\n",
    "    df[col + '_punctuations_by_words'] = df[col + '_num_punctuations'] / (df[col + '_num_words'] + 1)\n",
    "    df[col + '_digits_by_chars'] = df[col + '_num_digits'] / (df[col + '_num_chars'] + 1)\n",
    "    df[col + '_alphabets_by_chars'] = df[col + '_num_alphabets'] / (df[col + '_num_chars'] + 1)\n",
    "    df[col + '_stopwords_by_words'] = df[col + '_num_stopwords'] / (df[col + '_num_words'] + 1)\n",
    "    df[col + '_mean'] = df[col].apply(lambda x: 0 if len(x) == 0 else float(len(x.split())) / len(x)) * 10\n",
    "print(df.columns)\n",
    "df['title_description_len_ratio'] = (df['title_num_chars'].astype(np.float)) / (df['description_num_chars'].astype(np.float) + 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2011862, 37)\n",
      "Memory usage of dataframe is 592.57 MB\n",
      "Memory usage after optimization is: 233.78 MB\n",
      "Decreased by 60.5%\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df.drop(['title', 'description'], axis=1)\n",
    "df = reduce_mem_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 35)\n",
      "(508438, 35)\n"
     ]
    }
   ],
   "source": [
    "train = df[:lentrain]\n",
    "test = df[lentrain:]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "train.to_feather('../features/train/textfeatures_train.feather')\n",
    "test.to_feather('../features/test/textfeatures_test.feather')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 2)\n",
      "(508438, 2)\n"
     ]
    }
   ],
   "source": [
    "# Wordbatch\n",
    "train = pd.read_csv('../input/train.csv', usecols=['description', 'title'])\n",
    "test = pd.read_csv('../input/test.csv', usecols=['description', 'title'])\n",
    "\n",
    "for col in textfeats:\n",
    "    train[col] = train[col].astype(str)\n",
    "    train[col] = train[col].fillna('missing')\n",
    "    train[col] = train[col].str.lower()\n",
    "    train[col] = train[col].apply(lambda x: cleanName(x))\n",
    "for col in textfeats:\n",
    "    test[col] = test[col].astype(str)\n",
    "    test[col] = test[col].fillna('missing')\n",
    "    test[col] = test[col].str.lower()\n",
    "    test[col] = test[col].apply(lambda x: cleanName(x))\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize text\n",
      "Parallelization fail. Method: multiprocessing Task: <function batch_normalize_texts at 0x000001D382BA5D08>\n",
      "Retrying, attempt: 1 timeout limit: 1200 seconds\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wb = wordbatch.WordBatch(normalize_text, extractor=(WordBag, {\"hash_ngrams\": 2,\n",
    "                                                              \"hash_ngrams_weights\": [1.5, 1.0],\n",
    "                                                              \"hash_size\": 2 ** 29,\n",
    "                                                              \"norm\": None,\n",
    "                                                              \"tf\": 'binary',\n",
    "                                                              \"idf\": None,\n",
    "                                                              }), procs=8)\n",
    "wb.dictionary_freeze = True\n",
    "X_name_train = wb.fit_transform(train['title'])\n",
    "print(X_name_train.shape)\n",
    "X_name_test = wb.transform(test['title'])\n",
    "print(X_name_test.shape)\n",
    "del(wb)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 152827)\n",
      "(508438, 152827)\n",
      "Wall time: 9.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mask = np.where(X_name_train.getnnz(axis=0) > 3)[0]\n",
    "X_name_train = X_name_train[:, mask]\n",
    "print(X_name_train.shape)\n",
    "X_name_test = X_name_test[:, mask]\n",
    "print(X_name_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 167044)\n",
      "(508438, 167044)\n"
     ]
    }
   ],
   "source": [
    "# From pickle file\n",
    "with open('./wordbatch_title_train.pickle', 'rb') as f:\n",
    "    X_name_train = pickle.load(f)\n",
    "with open('./wordbatch_title_test.pickle', 'rb') as f:\n",
    "    X_name_test = pickle.load(f)\n",
    "\n",
    "print(X_name_train.shape)\n",
    "print(X_name_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deal_probability    0.235494\n",
      "dtype: float64\n",
      "deal_probability    0.235297\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y = pd.read_csv('../input/train.csv', usecols=['deal_probability'])\n",
    "\n",
    "X_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(X_name_train,\n",
    "                                                              y,\n",
    "                                                              test_size = 0.5,\n",
    "                                                              shuffle = False)\n",
    "model = Ridge(solver=\"sag\", fit_intercept=True, random_state=42, alpha=5)\n",
    "model.fit(X_train_1, y_train_1)\n",
    "train_ridge = model.predict(X_name_train)\n",
    "test_ridge = model.predict(X_name_test)\n",
    "print(rmse(model.predict(X_train_2), y_train_2))\n",
    "\n",
    "model = Ridge(solver=\"sag\", fit_intercept=True, random_state=4882, alpha=5)\n",
    "model.fit(X_train_2, y_train_2)\n",
    "train_ridge += model.predict(X_name_train)\n",
    "test_ridge += model.predict(X_name_test)\n",
    "print(rmse(model.predict(X_train_1), y_train_1))\n",
    "\n",
    "train_ridge /= 2.0\n",
    "test_ridge /= 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 1)\n",
      "(508438, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordbach_title_ridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.255343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.155275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.417688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.361951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wordbach_title_ridge\n",
       "0              0.061688\n",
       "1              0.255343\n",
       "2              0.155275\n",
       "3              0.417688\n",
       "4              0.361951"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ridgedf = pd.DataFrame()\n",
    "train_ridgedf['wordbach_title_ridge'] = train_ridge.flatten()\n",
    "test_ridgedf = pd.DataFrame()\n",
    "test_ridgedf['wordbach_title_ridge'] = test_ridge.flatten()\n",
    "\n",
    "print(train_ridgedf.shape)\n",
    "print(test_ridgedf.shape)\n",
    "\n",
    "train_ridgedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 11.47 MB\n",
      "Memory usage after optimization is: 5.74 MB\n",
      "Decreased by 50.0%\n",
      "Memory usage of dataframe is 3.88 MB\n",
      "Memory usage after optimization is: 1.94 MB\n",
      "Decreased by 50.0%\n",
      "(1503424, 1)\n",
      "(508438, 1)\n"
     ]
    }
   ],
   "source": [
    "train_ridgedf.reset_index(drop=True, inplace=True)\n",
    "test_ridgedf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_ridgedf = reduce_mem_usage(train_ridgedf)\n",
    "test_ridgedf = reduce_mem_usage(test_ridgedf)\n",
    "\n",
    "print(train_ridgedf.shape)\n",
    "print(test_ridgedf.shape)\n",
    "\n",
    "train_ridgedf.to_feather('../features/train/wordbatch_title_ridge_train.feather')\n",
    "test_ridgedf.to_feather('../features/test/wordbatch_title_ridge_test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_ridgedf, test_ridgedf, X_train_1, X_train_2, y_train_1, y_train_2, train_ridge, test_ridge\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 7)\n",
      "(508438, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svd_wordbatch_title_1</th>\n",
       "      <th>svd_wordbatch_title_2</th>\n",
       "      <th>svd_wordbatch_title_3</th>\n",
       "      <th>svd_wordbatch_title_4</th>\n",
       "      <th>svd_wordbatch_title_5</th>\n",
       "      <th>svd_wordbatch_title_6</th>\n",
       "      <th>svd_wordbatch_title_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.769956</td>\n",
       "      <td>-0.179334</td>\n",
       "      <td>-0.212950</td>\n",
       "      <td>0.023352</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>-0.032338</td>\n",
       "      <td>-0.048753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.878044</td>\n",
       "      <td>-0.134059</td>\n",
       "      <td>-0.242300</td>\n",
       "      <td>0.022084</td>\n",
       "      <td>-0.011211</td>\n",
       "      <td>0.042688</td>\n",
       "      <td>-0.023846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.772842</td>\n",
       "      <td>-0.179895</td>\n",
       "      <td>-0.212869</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>-0.000354</td>\n",
       "      <td>-0.032753</td>\n",
       "      <td>-0.048281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.816381</td>\n",
       "      <td>-0.185720</td>\n",
       "      <td>-0.222293</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.038439</td>\n",
       "      <td>-0.061262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000783</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.000959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   svd_wordbatch_title_1  svd_wordbatch_title_2  svd_wordbatch_title_3  \\\n",
       "0               1.769956              -0.179334              -0.212950   \n",
       "1               1.878044              -0.134059              -0.242300   \n",
       "2               1.772842              -0.179895              -0.212869   \n",
       "3               1.816381              -0.185720              -0.222293   \n",
       "4               0.000783              -0.000041              -0.000222   \n",
       "\n",
       "   svd_wordbatch_title_4  svd_wordbatch_title_5  svd_wordbatch_title_6  \\\n",
       "0               0.023352              -0.000302              -0.032338   \n",
       "1               0.022084              -0.011211               0.042688   \n",
       "2               0.022700              -0.000354              -0.032753   \n",
       "3               0.023900              -0.000044              -0.038439   \n",
       "4               0.000084              -0.000092               0.000755   \n",
       "\n",
       "   svd_wordbatch_title_7  \n",
       "0              -0.048753  \n",
       "1              -0.023846  \n",
       "2              -0.048281  \n",
       "3              -0.061262  \n",
       "4               0.000959  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_comp = 7\n",
    "tsvd = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "tsvd.fit(X_name_train)\n",
    "\n",
    "train_svd = pd.DataFrame(tsvd.transform(X_name_train))\n",
    "test_svd = pd.DataFrame(tsvd.transform(X_name_test))\n",
    "train_svd.columns = ['svd_wordbatch_title_'+str(i+1) for i in range(n_comp)]\n",
    "test_svd.columns =  ['svd_wordbatch_title_'+str(i+1) for i in range(n_comp)]\n",
    "\n",
    "print(train_svd.shape)\n",
    "print(test_svd.shape)\n",
    "train_svd.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 80.29 MB\n",
      "Memory usage after optimization is: 40.15 MB\n",
      "Decreased by 50.0%\n",
      "Memory usage of dataframe is 27.15 MB\n",
      "Memory usage after optimization is: 13.58 MB\n",
      "Decreased by 50.0%\n",
      "(1503424, 7)\n",
      "(508438, 7)\n"
     ]
    }
   ],
   "source": [
    "train_svd.reset_index(drop=True, inplace=True)\n",
    "test_svd.reset_index(drop=True, inplace=True)\n",
    "train_svd = reduce_mem_usage(train_svd)\n",
    "test_svd = reduce_mem_usage(test_svd)\n",
    "print(train_svd.shape)\n",
    "print(test_svd.shape)\n",
    "train_svd.to_feather('../features/train/wordbatch_title_tsvd_train.feather')\n",
    "test_svd.to_feather('../features/test/wordbatch_title_tsvd_test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 2)\n",
      "(508438, 2)\n"
     ]
    }
   ],
   "source": [
    "# Wordbatch\n",
    "train = pd.read_csv('../input/train.csv', usecols=['description', 'title'])\n",
    "test = pd.read_csv('../input/test.csv', usecols=['description', 'title'])\n",
    "\n",
    "for col in textfeats:\n",
    "    train[col] = train[col].astype(str)\n",
    "    train[col] = train[col].fillna('missing')\n",
    "    train[col] = train[col].str.lower()\n",
    "    train[col] = train[col].apply(lambda x: cleanName(x))\n",
    "for col in textfeats:\n",
    "    test[col] = test[col].astype(str)\n",
    "    test[col] = test[col].fillna('missing')\n",
    "    test[col] = test[col].str.lower()\n",
    "    test[col] = test[col].apply(lambda x: cleanName(x))\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize text\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wb = wordbatch.WordBatch(normalize_text, extractor=(WordBag, {\"hash_ngrams\": 2,\n",
    "                                                              \"hash_ngrams_weights\": [1.0, 1.0],\n",
    "                                                              \"hash_size\": 2 ** 28,\n",
    "                                                              \"norm\": \"l2\",\n",
    "                                                              \"tf\": 1.0,\n",
    "                                                              \"idf\": None,\n",
    "                                                              }), procs=8)\n",
    "wb.dictionary_freeze = True\n",
    "X_desc_train = wb.fit_transform(train['description'])\n",
    "print(X_desc_train.shape)\n",
    "X_desc_test = wb.transform(test['description'])\n",
    "print(X_desc_test.shape)\n",
    "del(wb)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mask = np.where(X_desc_train.getnnz(axis=0) > 3)[0]\n",
    "X_desc_train = X_desc_train[:, mask]\n",
    "print(X_desc_train.shape)\n",
    "X_desc_test = X_desc_test[:, mask]\n",
    "print(X_desc_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 1167053)\n",
      "(508438, 1167053)\n"
     ]
    }
   ],
   "source": [
    "# From pickle file\n",
    "with open('./wordbatch_description_train.pickle', 'rb') as f:\n",
    "    X_desc_train = pickle.load(f)\n",
    "with open('./wordbatch_description_test.pickle', 'rb') as f:\n",
    "    X_desc_test = pickle.load(f)\n",
    "\n",
    "print(X_desc_train.shape)\n",
    "print(X_desc_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deal_probability    0.231224\n",
      "dtype: float64\n",
      "deal_probability    0.23102\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y = pd.read_csv('../input/train.csv', usecols=['deal_probability'])\n",
    "\n",
    "X_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(X_desc_train,\n",
    "                                                              y,\n",
    "                                                              test_size = 0.5,\n",
    "                                                              shuffle = False)\n",
    "model = Ridge(solver=\"sag\", fit_intercept=True, random_state=42, alpha=5)\n",
    "model.fit(X_train_1, y_train_1)\n",
    "train_ridge = model.predict(X_desc_train)\n",
    "test_ridge = model.predict(X_desc_test)\n",
    "print(rmse(model.predict(X_train_2), y_train_2))\n",
    "\n",
    "model = Ridge(solver=\"sag\", fit_intercept=True, random_state=4882, alpha=5)\n",
    "model.fit(X_train_2, y_train_2)\n",
    "train_ridge += model.predict(X_desc_train)\n",
    "test_ridge += model.predict(X_desc_test)\n",
    "print(rmse(model.predict(X_train_1), y_train_1))\n",
    "\n",
    "train_ridge /= 2.0\n",
    "test_ridge /= 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 1)\n",
      "(508438, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordbach_description_ridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.133309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.137209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.191281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.433400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.358012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wordbach_description_ridge\n",
       "0                    0.133309\n",
       "1                    0.137209\n",
       "2                    0.191281\n",
       "3                    0.433400\n",
       "4                    0.358012"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ridgedf = pd.DataFrame()\n",
    "train_ridgedf['wordbach_description_ridge'] = train_ridge.flatten()\n",
    "test_ridgedf = pd.DataFrame()\n",
    "test_ridgedf['wordbach_description_ridge'] = test_ridge.flatten()\n",
    "\n",
    "print(train_ridgedf.shape)\n",
    "print(test_ridgedf.shape)\n",
    "\n",
    "train_ridgedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 11.47 MB\n",
      "Memory usage after optimization is: 5.74 MB\n",
      "Decreased by 50.0%\n",
      "Memory usage of dataframe is 3.88 MB\n",
      "Memory usage after optimization is: 1.94 MB\n",
      "Decreased by 50.0%\n",
      "(1503424, 1)\n",
      "(508438, 1)\n"
     ]
    }
   ],
   "source": [
    "train_ridgedf.reset_index(drop=True, inplace=True)\n",
    "test_ridgedf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_ridgedf = reduce_mem_usage(train_ridgedf)\n",
    "test_ridgedf = reduce_mem_usage(test_ridgedf)\n",
    "\n",
    "print(train_ridgedf.shape)\n",
    "print(test_ridgedf.shape)\n",
    "\n",
    "train_ridgedf.to_feather('../features/train/wordbatch_description_ridge_train.feather')\n",
    "test_ridgedf.to_feather('../features/test/wordbatch_description_ridge_test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_ridgedf, test_ridgedf, X_train_1, X_train_2, y_train_1, y_train_2, train_ridge, test_ridge\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 7)\n",
      "(508438, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svd_wordbatch_description_1</th>\n",
       "      <th>svd_wordbatch_description_2</th>\n",
       "      <th>svd_wordbatch_description_3</th>\n",
       "      <th>svd_wordbatch_description_4</th>\n",
       "      <th>svd_wordbatch_description_5</th>\n",
       "      <th>svd_wordbatch_description_6</th>\n",
       "      <th>svd_wordbatch_description_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010941</td>\n",
       "      <td>-0.004648</td>\n",
       "      <td>0.011228</td>\n",
       "      <td>0.005028</td>\n",
       "      <td>-0.009737</td>\n",
       "      <td>-0.002559</td>\n",
       "      <td>0.007509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001629</td>\n",
       "      <td>-0.000355</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.226791</td>\n",
       "      <td>-0.134340</td>\n",
       "      <td>-0.129719</td>\n",
       "      <td>-0.164746</td>\n",
       "      <td>-0.053011</td>\n",
       "      <td>-0.002977</td>\n",
       "      <td>-0.027714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.125448</td>\n",
       "      <td>-0.046120</td>\n",
       "      <td>0.223455</td>\n",
       "      <td>-0.043587</td>\n",
       "      <td>0.185580</td>\n",
       "      <td>-0.065177</td>\n",
       "      <td>-0.037679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019432</td>\n",
       "      <td>-0.010822</td>\n",
       "      <td>0.013322</td>\n",
       "      <td>-0.010144</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.023814</td>\n",
       "      <td>-0.011581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   svd_wordbatch_description_1  svd_wordbatch_description_2  \\\n",
       "0                     0.010941                    -0.004648   \n",
       "1                     0.001629                    -0.000355   \n",
       "2                     0.226791                    -0.134340   \n",
       "3                     0.125448                    -0.046120   \n",
       "4                     0.019432                    -0.010822   \n",
       "\n",
       "   svd_wordbatch_description_3  svd_wordbatch_description_4  \\\n",
       "0                     0.011228                     0.005028   \n",
       "1                     0.001153                     0.000376   \n",
       "2                    -0.129719                    -0.164746   \n",
       "3                     0.223455                    -0.043587   \n",
       "4                     0.013322                    -0.010144   \n",
       "\n",
       "   svd_wordbatch_description_5  svd_wordbatch_description_6  \\\n",
       "0                    -0.009737                    -0.002559   \n",
       "1                    -0.001365                     0.000309   \n",
       "2                    -0.053011                    -0.002977   \n",
       "3                     0.185580                    -0.065177   \n",
       "4                     0.000830                     0.023814   \n",
       "\n",
       "   svd_wordbatch_description_7  \n",
       "0                     0.007509  \n",
       "1                     0.001030  \n",
       "2                    -0.027714  \n",
       "3                    -0.037679  \n",
       "4                    -0.011581  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_comp = 7\n",
    "tsvd = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "tsvd.fit(X_desc_train)\n",
    "\n",
    "train_svd = pd.DataFrame(tsvd.transform(X_desc_train))\n",
    "test_svd = pd.DataFrame(tsvd.transform(X_desc_test))\n",
    "train_svd.columns = ['svd_wordbatch_description_'+str(i+1) for i in range(n_comp)]\n",
    "test_svd.columns =  ['svd_wordbatch_description_'+str(i+1) for i in range(n_comp)]\n",
    "\n",
    "print(train_svd.shape)\n",
    "print(test_svd.shape)\n",
    "train_svd.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 80.29 MB\n",
      "Memory usage after optimization is: 40.15 MB\n",
      "Decreased by 50.0%\n",
      "Memory usage of dataframe is 27.15 MB\n",
      "Memory usage after optimization is: 13.58 MB\n",
      "Decreased by 50.0%\n",
      "(1503424, 7)\n",
      "(508438, 7)\n"
     ]
    }
   ],
   "source": [
    "train_svd.reset_index(drop=True, inplace=True)\n",
    "test_svd.reset_index(drop=True, inplace=True)\n",
    "train_svd = reduce_mem_usage(train_svd)\n",
    "test_svd = reduce_mem_usage(test_svd)\n",
    "print(train_svd.shape)\n",
    "print(test_svd.shape)\n",
    "train_svd.to_feather('../features/train/wordbatch_description_tsvd_train.feather')\n",
    "test_svd.to_feather('../features/test/wordbatch_description_tsvd_test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./wordbatch_title_train.pickle', 'rb') as f:\n",
    "    X_name_train = pickle.load(f)\n",
    "with open('./wordbatch_title_test.pickle', 'rb') as f:\n",
    "    X_name_test = pickle.load(f)\n",
    "with open('./wordbatch_description_train.pickle', 'rb') as f:\n",
    "    X_desc_train = pickle.load(f)\n",
    "with open('./wordbatch_description_test.pickle', 'rb') as f:\n",
    "    X_desc_test = pickle.load(f)\n",
    "\n",
    "print(X_name_train.shape)\n",
    "print(X_name_test.shape)\n",
    "print(X_desc_train.shape)\n",
    "print(X_desc_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 1334097)\n",
      "parent_category_name\n",
      "(1503424, 1334106)\n",
      "category_name\n",
      "(1503424, 1334153)\n",
      "user_type\n",
      "(1503424, 1334156)\n",
      "region\n",
      "(1503424, 1334184)\n",
      "city\n",
      "(1503424, 1335917)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "514"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Emsemble\n",
    "dummy_cols = ['parent_category_name', 'category_name', 'user_type',\n",
    "            'region', 'city']\n",
    "df_train = pd.read_csv('../input/train.csv', usecols=dummy_cols)\n",
    "df_test  = pd.read_csv('../input/test.csv' , usecols=dummy_cols)\n",
    "y_train = pd.read_csv('../input/train.csv', usecols=['deal_probability'])\n",
    "\n",
    "sparse_merge_train = hstack((X_name_train, X_desc_train)).tocsr()\n",
    "sparse_merge_test = hstack((X_name_test, X_desc_test)).tocsr()\n",
    "print(sparse_merge_train.shape)\n",
    "for col in dummy_cols:\n",
    "    print(col)\n",
    "    lb = LabelBinarizer(sparse_output=True)\n",
    "    sparse_merge_train = hstack((sparse_merge_train, lb.fit_transform(df_train[[col]].fillna('')))).tocsr()\n",
    "    print(sparse_merge_train.shape)\n",
    "    sparse_merge_test = hstack((sparse_merge_test, lb.transform(df_test[[col]].fillna('')))).tocsr()\n",
    "\n",
    "del X_desc_test, X_name_test\n",
    "del X_desc_train, X_name_train, lb, df_train, df_test\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deal_probability    0.234367\n",
      "dtype: float64\n",
      "deal_probability    0.232109\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train_1, X_train_2, y_train_1, y_train_2 = train_test_split(sparse_merge_train, y_train,\n",
    "                                                              test_size = 0.5,\n",
    "                                                              shuffle = False)\n",
    "\n",
    "model = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3.3)\n",
    "model.fit(X_train_1, y_train_1)\n",
    "train_ridge = model.predict(sparse_merge_train)\n",
    "test_ridge = model.predict(sparse_merge_test)\n",
    "print(rmse(model.predict(X_train_2), y_train_2))\n",
    "\n",
    "model = Ridge(solver=\"sag\", fit_intercept=True, random_state=4882, alpha=5)\n",
    "model.fit(X_train_2, y_train_2)\n",
    "train_ridge += model.predict(sparse_merge_train)\n",
    "test_ridge += model.predict(sparse_merge_test)\n",
    "print(rmse(model.predict(X_train_1), y_train_1))\n",
    "\n",
    "train_ridge /= 2.0\n",
    "test_ridge /= 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 1)\n",
      "(508438, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordbach_ensemble_ridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.178658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.422455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wordbach_ensemble_ridge\n",
       "0                 0.069136\n",
       "1                 0.210749\n",
       "2                 0.178658\n",
       "3                 0.422455\n",
       "4                 0.330381"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ridgedf = pd.DataFrame()\n",
    "train_ridgedf['wordbach_ensemble_ridge'] = train_ridge.flatten()\n",
    "test_ridgedf = pd.DataFrame()\n",
    "test_ridgedf['wordbach_ensemble_ridge'] = test_ridge.flatten()\n",
    "\n",
    "print(train_ridgedf.shape)\n",
    "print(test_ridgedf.shape)\n",
    "\n",
    "train_ridgedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 11.47 MB\n",
      "Memory usage after optimization is: 5.74 MB\n",
      "Decreased by 50.0%\n",
      "Memory usage of dataframe is 3.88 MB\n",
      "Memory usage after optimization is: 1.94 MB\n",
      "Decreased by 50.0%\n",
      "(1503424, 1)\n",
      "(508438, 1)\n"
     ]
    }
   ],
   "source": [
    "train_ridgedf.reset_index(drop=True, inplace=True)\n",
    "test_ridgedf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_ridgedf = reduce_mem_usage(train_ridgedf)\n",
    "test_ridgedf = reduce_mem_usage(test_ridgedf)\n",
    "\n",
    "print(train_ridgedf.shape)\n",
    "print(test_ridgedf.shape)\n",
    "\n",
    "train_ridgedf.to_feather('../features/train/wordbatch_ensemble_ridge_train.feather')\n",
    "test_ridgedf.to_feather('../features/test/wordbatch_ensemble_ridge_test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 7)\n",
      "(508438, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svd_wordbatch_ensemble_1</th>\n",
       "      <th>svd_wordbatch_ensemble_2</th>\n",
       "      <th>svd_wordbatch_ensemble_3</th>\n",
       "      <th>svd_wordbatch_ensemble_4</th>\n",
       "      <th>svd_wordbatch_ensemble_5</th>\n",
       "      <th>svd_wordbatch_ensemble_6</th>\n",
       "      <th>svd_wordbatch_ensemble_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.037161</td>\n",
       "      <td>-0.831009</td>\n",
       "      <td>-0.269284</td>\n",
       "      <td>0.221150</td>\n",
       "      <td>-0.265321</td>\n",
       "      <td>-0.072668</td>\n",
       "      <td>-0.088566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.834982</td>\n",
       "      <td>-1.216466</td>\n",
       "      <td>-0.321711</td>\n",
       "      <td>0.113050</td>\n",
       "      <td>-0.007616</td>\n",
       "      <td>-0.010484</td>\n",
       "      <td>-0.269372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.744941</td>\n",
       "      <td>-1.184826</td>\n",
       "      <td>-0.271241</td>\n",
       "      <td>0.082087</td>\n",
       "      <td>0.017441</td>\n",
       "      <td>0.027664</td>\n",
       "      <td>-0.302406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.693178</td>\n",
       "      <td>-0.956834</td>\n",
       "      <td>-0.272879</td>\n",
       "      <td>0.111852</td>\n",
       "      <td>0.235998</td>\n",
       "      <td>0.017325</td>\n",
       "      <td>1.069096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.552597</td>\n",
       "      <td>0.019953</td>\n",
       "      <td>0.086612</td>\n",
       "      <td>0.054564</td>\n",
       "      <td>-0.548707</td>\n",
       "      <td>-0.090681</td>\n",
       "      <td>-1.342931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   svd_wordbatch_ensemble_1  svd_wordbatch_ensemble_2  \\\n",
       "0                  2.037161                 -0.831009   \n",
       "1                  1.834982                 -1.216466   \n",
       "2                  1.744941                 -1.184826   \n",
       "3                  1.693178                 -0.956834   \n",
       "4                  0.552597                  0.019953   \n",
       "\n",
       "   svd_wordbatch_ensemble_3  svd_wordbatch_ensemble_4  \\\n",
       "0                 -0.269284                  0.221150   \n",
       "1                 -0.321711                  0.113050   \n",
       "2                 -0.271241                  0.082087   \n",
       "3                 -0.272879                  0.111852   \n",
       "4                  0.086612                  0.054564   \n",
       "\n",
       "   svd_wordbatch_ensemble_5  svd_wordbatch_ensemble_6  \\\n",
       "0                 -0.265321                 -0.072668   \n",
       "1                 -0.007616                 -0.010484   \n",
       "2                  0.017441                  0.027664   \n",
       "3                  0.235998                  0.017325   \n",
       "4                 -0.548707                 -0.090681   \n",
       "\n",
       "   svd_wordbatch_ensemble_7  \n",
       "0                 -0.088566  \n",
       "1                 -0.269372  \n",
       "2                 -0.302406  \n",
       "3                  1.069096  \n",
       "4                 -1.342931  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_comp = 7\n",
    "tsvd = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "tsvd.fit(sparse_merge_train)\n",
    "\n",
    "train_svd = pd.DataFrame(tsvd.transform(sparse_merge_train))\n",
    "test_svd = pd.DataFrame(tsvd.transform(sparse_merge_test))\n",
    "train_svd.columns = ['svd_wordbatch_ensemble_'+str(i+1) for i in range(n_comp)]\n",
    "test_svd.columns =  ['svd_wordbatch_ensemble_'+str(i+1) for i in range(n_comp)]\n",
    "\n",
    "print(train_svd.shape)\n",
    "print(test_svd.shape)\n",
    "train_svd.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 80.29 MB\n",
      "Memory usage after optimization is: 40.15 MB\n",
      "Decreased by 50.0%\n",
      "Memory usage of dataframe is 27.15 MB\n",
      "Memory usage after optimization is: 13.58 MB\n",
      "Decreased by 50.0%\n",
      "(1503424, 7)\n",
      "(508438, 7)\n"
     ]
    }
   ],
   "source": [
    "train_svd.reset_index(drop=True, inplace=True)\n",
    "test_svd.reset_index(drop=True, inplace=True)\n",
    "train_svd = reduce_mem_usage(train_svd)\n",
    "test_svd = reduce_mem_usage(test_svd)\n",
    "print(train_svd.shape)\n",
    "print(test_svd.shape)\n",
    "train_svd.to_feather('../features/train/wordbatch_ensemble_tsvd_train.feather')\n",
    "test_svd.to_feather('../features/test/wordbatch_ensemble_tsvd_test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
